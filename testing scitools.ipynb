{
 "metadata": {
  "name": "testing scitools"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scitools.MovingPlotWindow as MovingPlotWindow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help MovingPlotWindow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on module scitools.MovingPlotWindow in scitools:\n",
        "\n",
        "NAME\n",
        "    scitools.MovingPlotWindow - Manage a moving plot window for displaying very long time series.\n",
        "\n",
        "FILE\n",
        "    /usr/lib/python2.7/site-packages/scitools/MovingPlotWindow.py\n",
        "\n",
        "CLASSES\n",
        "    MovingPlotWindow\n",
        "    \n",
        "    class MovingPlotWindow\n",
        "     |  Make a plot window that follows the tip (end) of a very long\n",
        "     |  time series.\n",
        "     |  \n",
        "     |  Example::\n",
        "     |  \n",
        "     |      def demo(I, k, dt, T, mode='continuous movement'):\n",
        "     |          \"\"\"\n",
        "     |          Solve u' = -k**2*u, u(0)=I, u'(0)=0 by a finite difference\n",
        "     |          method with time steps dt, from t=0 to t=T.\n",
        "     |          \"\"\"\n",
        "     |          if dt > 2./k:\n",
        "     |              print 'Unstable scheme'\n",
        "     |          N = int(round(T/float(dt)))\n",
        "     |          u = zeros(N+1)\n",
        "     |          t = linspace(0, T, N+1)\n",
        "     |  \n",
        "     |          umin = -1.2*I\n",
        "     |          umax = -umin\n",
        "     |          period = 2*pi/k  # period of the oscillations\n",
        "     |          window_width =\n",
        "     |          plot_manager = MovingPlotWindow(\n",
        "     |                           window_width, dt, yaxis=[umin, umax],\n",
        "     |                           mode=mode)\n",
        "     |          u[0] = I\n",
        "     |          u[1] = u[0] - 0.5*dt**2*k**2*u[0]\n",
        "     |          for n in range(1,N):\n",
        "     |              u[n+1] = 2*u[n] - u[n-1] - dt**2*k**2*u[n]\n",
        "     |  \n",
        "     |              if plot_manager.plot(n):\n",
        "     |                  s = plot_manager.first_index_in_plot\n",
        "     |                  plot(t[s:n+2], u[s:n+2], 'r-',\n",
        "     |                       t[s:n+2], I*cos(k*t)[s:n+2], 'b-',\n",
        "     |                       axis=plot_manager.axis(),\n",
        "     |                       title=\"Solution of u'' + k^2 u = 0 for t=%6.3f (mode: %s)\" % (t[n+1], mode))\n",
        "     |              plot_manager.update(n)\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, window_width, dt, yaxis=[-1, 1], mode='continuous movement', pause=1.5)\n",
        "     |      ====================  ====================================\n",
        "     |      Argument              Description\n",
        "     |      ====================  ====================================\n",
        "     |      window_width          tmax-tmin in a plot window\n",
        "     |      dt                    time step (constant)\n",
        "     |      yaxis                 extent of y axis\n",
        "     |      mode                  method for moving the plot window,\n",
        "     |                            see below.\n",
        "     |      ====================  ====================================\n",
        "     |      \n",
        "     |      The mode parameter has three values:\n",
        "     |      \n",
        "     |        * ``'continuous movement'``:\n",
        "     |          the plot window moves one time step for each plot.\n",
        "     |        * ``'continuous drawing'``: the curves are drawn from left\n",
        "     |          to right, one step at a time, and plot window jumps\n",
        "     |          when the curve reaches the end.\n",
        "     |        * ``'jumps'``: the curves are shown in a window for a time\n",
        "     |          equal to the pause argument, then the axis jumps\n",
        "     |          to a new time window of the same length\n",
        "     |      \n",
        "     |      \n",
        "     |      See also the test block of the module for\n",
        "     |      testing out the three different modes of this class.\n",
        "     |  \n",
        "     |  axis(self)\n",
        "     |      Return the axis limits as a list ``[xmin, xmax, ymin, ymax]``.\n",
        "     |  \n",
        "     |  plot(self, n)\n",
        "     |      Return True if a plot is to be drawn at time step number ``n``,\n",
        "     |      otherwise return False.\n",
        "     |  \n",
        "     |  update(self, n)\n",
        "     |      Update the plot manager (``MovingPlotWindow``) at time step ``n``.\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scitools.TkGUI as TkGUI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help TkGUI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on module scitools.TkGUI in scitools:\n",
        "\n",
        "NAME\n",
        "    scitools.TkGUI\n",
        "\n",
        "FILE\n",
        "    /usr/lib/python2.7/site-packages/scitools/TkGUI.py\n",
        "\n",
        "DESCRIPTION\n",
        "    Module with functions and classes used in the GUI chapters of\n",
        "    the book \"Python Scripting for Computational Science\".\n",
        "\n",
        "CLASSES\n",
        "    AutoSimVizCGI\n",
        "    AutoSimVizGUI\n",
        "    CanvasCoords\n",
        "    DrawFunction\n",
        "    DrawFunctionDialog\n",
        "    FuncDependenceViz\n",
        "    FuncSpec\n",
        "    FunctionChoices\n",
        "    FunctionSelector\n",
        "    InputPrm\n",
        "        InputPrmCGI\n",
        "        InputPrmGUI\n",
        "    Parameters\n",
        "    StringFormula\n",
        "    UserFunction\n",
        "        Drawing\n",
        "    \n",
        "    class AutoSimVizCGI\n",
        "     |  Organize a set of form variables for input data.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self)\n",
        "     |  \n",
        "     |  footer(self)\n",
        "     |      Write out HTML footer instructions.\n",
        "     |  \n",
        "     |  make(self, form, parameters, CGI_script, imagefile=None)\n",
        "     |      Create an HTML page consisting of an optional\n",
        "     |      image (specified by imagefile), a table of form variables\n",
        "     |      (specified by parameters (scitools.ParameterInterface.Parameters)),\n",
        "     |      and a \"simulate and visualize\" button.\n",
        "     |      The resulting visualization part must be created after\n",
        "     |      calling this function. Finally, the HTML page needs\n",
        "     |      a footer (see the footer function).\n",
        "    \n",
        "    class AutoSimVizGUI\n",
        "     |  Organize a set of widgets for input data together with\n",
        "     |  buttons for running a simulator and performing visualizations.\n",
        "     |  The input data are represented by a Parameters object\n",
        "     |  from the ParameterInterface module.\n",
        "     |  The individual parameters in this object are represented as\n",
        "     |  InputPrmGUI instances.\n",
        "     |  The application code creates Parameters object\n",
        "     |  (recall to call addend() after all parameters are registered).\n",
        "     |  \n",
        "     |  The method make_prmGUI takes the Parameters objects,\n",
        "     |  makes the associated widgets and packs them in an appropriate\n",
        "     |  GUI. All widgets may appear in one column, in the order the\n",
        "     |  parameters were registered in the Parameters object, if\n",
        "     |  sort_widgets is false. Otherwise, two column of widgets are\n",
        "     |  made: one with sliders and one with the rest (checkbuttons,\n",
        "     |  entries, options). The sequence of widgets in the latter case\n",
        "     |  is determined by the sequence of registration in the Parameters,\n",
        "     |  e.g., all sliders are grouped in their original sequence,\n",
        "     |  all option menus are grouped in their original sequence, and so on.\n",
        "     |  \n",
        "     |  The method make_buttonGUI creates buttons for simulation and\n",
        "     |  visualization, plus an optional logo and a help button.\n",
        "     |  If more buttons are wanted, one can add these to the\n",
        "     |  button_frame Tkinter.Frame attribute.\n",
        "     |  \n",
        "     |  There is an optional column of widgets with BLT graphs for\n",
        "     |  curve plotting, enabled by the make_curveplotGUI method.\n",
        "     |  \n",
        "     |  The great advantage of this class is that the application code\n",
        "     |  can concentrate on defining input parameters to a problem,\n",
        "     |  the simulation and visualization functions, and leave it to\n",
        "     |  this class to put everything together. It is then an easy task\n",
        "     |  to change the layout of the whole GUI in one common place.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self)\n",
        "     |  \n",
        "     |  load_curveplot(self, filename, graph, curvename='')\n",
        "     |      Load data from a two-column file into x and y Blt vectors.\n",
        "     |      graph is a Pmw.Blt.Graph widget, normally returned from\n",
        "     |      make_curveplotGUI.\n",
        "     |      \n",
        "     |      x, y = self.someGUI.load_curveplot('my.dat', self.plot2,\n",
        "     |                                      curvename='measured data')\n",
        "     |      \n",
        "     |      One can convert x and y, which are plain Python lists, to\n",
        "     |      NumPy arrays for further processing if desired.\n",
        "     |  \n",
        "     |  make_buttonGUI(self, parent, buttons=[], logo=None, help=None)\n",
        "     |  \n",
        "     |  make_curveplotGUI(self, parent, no_of_plotframes=1, placement='right')\n",
        "     |      @param parent: parent (master) widget\n",
        "     |      @param no_of_plotframes: no of graph areas\n",
        "     |      @param placement: placement of the plot area ('right' or 'bottom')\n",
        "     |      \n",
        "     |      Example on creating\n",
        "     |      three plot areas to the right in the window::\n",
        "     |      \n",
        "     |        self.plot1, self.plot2, self.plot3 =               self.someGUI.make_curveplotGUI(parent, 3, 'right')\n",
        "     |        self.plot1 etc. holds Pmw.Blt.Graph widgets.\n",
        "     |      \n",
        "     |      Create a single plot area::\n",
        "     |        self.plot1 = self.someGUI.make_curveplotGUI(parent,\n",
        "     |                                                    1, 'bottom')\n",
        "     |  \n",
        "     |  make_prmGUI(self, parent, parameters, sort_widgets=0, height=None, pane=0)\n",
        "     |      The height parameter controls the height (in pixels) of\n",
        "     |      the GUI.\n",
        "     |      \n",
        "     |      The columns are realized by Pmw.ScrolledFrame widgets.\n",
        "     |  \n",
        "     |  update_curveplot(self, filename, graph)\n",
        "     |      Update Blt vectors with data from a two-column file.\n",
        "    \n",
        "    class CanvasCoords\n",
        "     |  Utilities for transforming between canvas coordinates and\n",
        "     |  physical (real) coordinates.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self)\n",
        "     |  \n",
        "     |  c2p = canvas2physical(self, x, y)\n",
        "     |  \n",
        "     |  c2p4 = canvas2physical4(self, coords)\n",
        "     |  \n",
        "     |  canvas2physical(self, x, y)\n",
        "     |      Inverse of physical2canvas.\n",
        "     |  \n",
        "     |  canvas2physical4(self, coords)\n",
        "     |      Inverse of physical2canvas4.\n",
        "     |  \n",
        "     |  cx(self, x)\n",
        "     |      Transform physical x to canvas x.\n",
        "     |  \n",
        "     |  cy(self, y)\n",
        "     |      Transform physical y to canvas y.\n",
        "     |  \n",
        "     |  p2c = physical2canvas(self, x, y)\n",
        "     |  \n",
        "     |  p2c4 = physical2canvas4(self, coords)\n",
        "     |  \n",
        "     |  physical2canvas(self, x, y)\n",
        "     |      Transform physical (x,y) to canvas 2-tuple.\n",
        "     |  \n",
        "     |  physical2canvas4(self, coords)\n",
        "     |      Transform physical 4-tuple (x1,x2,y1,y2) to\n",
        "     |      canvas 4-tuple.\n",
        "     |  \n",
        "     |  print_coordinate_system(self)\n",
        "     |  \n",
        "     |  scale(self, dx)\n",
        "     |      Transform a length in canvas coordinates\n",
        "     |      to a length in physical coordinates.\n",
        "     |  \n",
        "     |  set_coordinate_system(self, canvas_width, canvas_height, x_origin, y_origin, x_range=1.0)\n",
        "     |      Define parameters in the physical coordinate system\n",
        "     |      (origin, width) expressed in canvas coordinates.\n",
        "     |      x_range is the width of canvas window in physical coordinates.\n",
        "    \n",
        "    class DrawFunction\n",
        "     |  Interactive drawing of y=f(x) functions.\n",
        "     |  The drawing takes place in a Pmw.Blt.Graph widget.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, xcoor, parent, ymin=0.0, ymax=1.0, width=500, height=200, curvename=' ', ylabel='', xlabel='', curvecolor='green', curvewidth=4, yrange_widgets=True)\n",
        "     |      Interactive drawing of a function.\n",
        "     |      \n",
        "     |      xcoor           grid points (on the x axsis) for interpolation\n",
        "     |      parent          parent widget\n",
        "     |      ymin, ymax      initial extent of the y axis\n",
        "     |      width, height   size of widget\n",
        "     |      curvename       name of function to be drawn\n",
        "     |      xlabel, ylabel  labels on the axis\n",
        "     |      curvecolor      color of the drawn curve\n",
        "     |      curvewidth      line thickness of the drawn curve\n",
        "     |      yrange_widgets  True: add text entries for range of y axis\n",
        "     |      \n",
        "     |      These parameters, except for parent and yrange_widgets,\n",
        "     |      can also be set as keyword arguments in the configure method.\n",
        "     |  \n",
        "     |  configure(self, **kwargs)\n",
        "     |      Legal parameters (kwargs):\n",
        "     |      \n",
        "     |      xcoor           grid points (on the x axsis) for interpolation\n",
        "     |      width, height   size of widget\n",
        "     |      curvename       name of function to be drawn\n",
        "     |      xlabel, ylabel  labels on the axis\n",
        "     |      curvecolor      color of the drawn curve\n",
        "     |      curvewidth      line thickness of the drawn curve\n",
        "     |      \n",
        "     |      ymin and ymax are set in set_yaxis method.\n",
        "     |  \n",
        "     |  erase(self)\n",
        "     |      delete all curves and make new empty self.x and self.y\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      return points (x,y), interpolated to the grid, where\n",
        "     |      x and y are NumPy arrays of coordinates\n",
        "     |  \n",
        "     |  interpolate(self)\n",
        "     |  \n",
        "     |  mouse_down(self, event)\n",
        "     |  \n",
        "     |  mouse_drag(self, event)\n",
        "     |  \n",
        "     |  mouse_up(self, event)\n",
        "     |  \n",
        "     |  pack(self, **kwargs)\n",
        "     |  \n",
        "     |  set_yaxis(self, ymin, ymax)\n",
        "    \n",
        "    class DrawFunctionDialog\n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, xcoor, parent=None)\n",
        "     |      Dialog box with DrawFunction widget\n",
        "     |  \n",
        "     |  action(self, result)\n",
        "     |  \n",
        "     |  get(self)\n",
        "    \n",
        "    class Drawing(UserFunction)\n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, parent, func_spec)\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Return function object.\n",
        "    \n",
        "    class FuncDependenceViz\n",
        "     |  Visualization of the shape of a function depends\n",
        "     |  continuously on its parameters, and this class\n",
        "     |  makes a graphical illustration of this dependence.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, master, parameter_intervals={}, functions={}, xmin=0.0, xmax=1.0, resolution=101, width=500, height=400, viztool='Pmw.Blt.Graph', plot_update='after')\n",
        "     |      Define a set of functions depending on a set of parameters.\n",
        "     |      This class creates a GUI where the parameters can be adjusted,\n",
        "     |      and the effect on the function graphs can be seen immediately.\n",
        "     |  \n",
        "     |  bind_vectors2BLTgraph(self)\n",
        "     |      bind vectors to the curves in the BLT graph\n",
        "     |  \n",
        "     |  fill_vectors(self)\n",
        "     |  \n",
        "     |  make_vectors(self)\n",
        "     |      make x vector and a dictionary of y vectors\n",
        "     |  \n",
        "     |  psdump(self, event=None)\n",
        "     |  \n",
        "     |  quit(self, event=None)\n",
        "     |      kill plot window\n",
        "     |  \n",
        "     |  visualize(self, var)\n",
        "    \n",
        "    class FuncSpec\n",
        "     |  Specification of a function.\n",
        "     |  Lists of such specifications can be fed to class FunctionSelector\n",
        "     |  to form a notebook where each page is designed according to the\n",
        "     |  contents of a FuncSpec object.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, representation, name='', parameters=None, independent_variables=[], formula=None, image=None, function_object=None, vector=0, description=None, xcoor=None, scrolled_frame=False)\n",
        "     |      Arguments:\n",
        "     |      \n",
        "     |      @param representation:  class Drawing, UserFunction, or\n",
        "     |                              StringFormula\n",
        "     |      @param name:            name of function\n",
        "     |      @param parameters:      parameters in the function, either\n",
        "     |                              dict or Parameters instance\n",
        "     |      @param independent_variables: list/tuple of strings with the\n",
        "     |                              names of the indep. variables.\n",
        "     |      @param formula:         textual doc of function formula\n",
        "     |      @param image:           filename of GIF image (LaTeX)\n",
        "     |      @param function_object: callable object for evaluating the function\n",
        "     |      @param vector:          0: scalar function, >0: no of vector comp.\n",
        "     |      @param description:     more verbose description than formula\n",
        "     |      @param xcoor:           array of coordinates for drawing\n",
        "     |      @param scrolled_frame:  scrollbars in the notebook page, False\n",
        "     |                              or dict: {'width': 300, 'height':200}\n",
        "     |      \n",
        "     |      Examples: see test_FunctionSelector in TkGUI.py.\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  configure(self, **kwargs)\n",
        "     |  \n",
        "     |  get_independent_variables(self)\n",
        "     |  \n",
        "     |  ok(self)\n",
        "    \n",
        "    class FunctionChoices\n",
        "     |  Notebook for various representations of a function.\n",
        "     |  The representations appear as pages. Each page is\n",
        "     |  realized as a UserFunction, StringFormula, or Drawing\n",
        "     |  instance.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, parent, func_spec_list)\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Return initialized function object corresponding to\n",
        "     |      the currently selected notebook page.\n",
        "    \n",
        "    class FunctionSelector\n",
        "     |  Notebook with a collection of functions to be specified.\n",
        "     |  Each function is represented by a FunctionChoices page.\n",
        "     |  This page is again a notebook with pages corresponding to\n",
        "     |  different ways of specifying a function:\n",
        "     |  drawing, string formulas, ready-made formulas with\n",
        "     |  free parameters, hardcoded Python functions etc.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, parent)\n",
        "     |  \n",
        "     |  add(self, name, func_spec_list)\n",
        "     |  \n",
        "     |  get(self, name)\n",
        "     |      Return initialized function object corresponding to\n",
        "     |      the page with the given name.\n",
        "     |  \n",
        "     |  pack(self, **kwargs)\n",
        "     |  \n",
        "     |  select(self, name, page)\n",
        "     |      Select page under the name tab.\n",
        "    \n",
        "    class InputPrm\n",
        "     |  Class for holding data about a parameter.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, name=None, default=0.0, str2type=None, help=None, unit=None, cmlarg=None, prmclass=None)\n",
        "     |      default           default value\n",
        "     |      str2type          string to type conversion\n",
        "     |                        (float, int, str, str2bool)\n",
        "     |      name              parameter name\n",
        "     |      help              description of parameter\n",
        "     |      unit              physical unit (dimension)\n",
        "     |      cmlarg            command-line argument for sending\n",
        "     |                        this prm to an external program\n",
        "     |      prmclass          classification of this parameter, e.g.,\n",
        "     |                        'numerics', 'physics', 'material', etc.\n",
        "     |      \n",
        "     |      Note: value with unit only works if str is float or int\n",
        "     |      \n",
        "     |      >>> p=InputPrm('q', 1, float, unit='m')\n",
        "     |      >>> p.set(6)\n",
        "     |      >>> p.get()\n",
        "     |      6.0\n",
        "     |      >>> p.set('6 cm')\n",
        "     |      >>> p.get()\n",
        "     |      0.059999999999999998\n",
        "     |      >>> p=InputPrm('q', '1 m', float, unit='m')\n",
        "     |      >>> p.set('1 km')\n",
        "     |      >>> p.get()\n",
        "     |      1000.0\n",
        "     |      >>> p.get_wunit()\n",
        "     |      '1000.0 m'\n",
        "     |      >>> p.unit\n",
        "     |      'm'\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |      Application of eval to this output creates the instance.\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |      Compact output; just the value as a formatted string.\n",
        "     |      Note that __str__ is used by __repr__ so strings must\n",
        "     |      be enclosed in quotes.\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Return the value of the parameter.\n",
        "     |  \n",
        "     |  getPhysicalQuantity(self)\n",
        "     |  \n",
        "     |  get_wunit(self)\n",
        "     |      Return value with unit (dimension) as string, if it has.\n",
        "     |      Otherwise, return value (with the right type).\n",
        "     |  \n",
        "     |  set(self, value)\n",
        "     |      Set the value of the parameter.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  v\n",
        "     |      value of parameter\n",
        "    \n",
        "    class InputPrmCGI(InputPrm)\n",
        "     |  Represent a parameter by a form variable in HTML.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, name=None, default=0.0, str2type=None, widget_type='entry', values=None, form=None, help=None, unit=None, cmlarg=None)\n",
        "     |      default            default value\n",
        "     |      str2type           function from string to type\n",
        "     |      name               name of parameter\n",
        "     |      widget_type        entry, slider, option, checkbutton\n",
        "     |      values             option values\n",
        "     |      form               cgi.FieldStorage object\n",
        "     |      help               description of parameter\n",
        "     |      unit               physical unit (dimension)\n",
        "     |      cmlarg             command-line argument for sending\n",
        "     |                         this prm to an external program\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |      Application of eval to this output creates the object.\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |  \n",
        "     |  make_form_entry(self)\n",
        "     |      Write the form's input field, according to widget_type.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from InputPrm:\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |      Compact output; just the value as a formatted string.\n",
        "     |      Note that __str__ is used by __repr__ so strings must\n",
        "     |      be enclosed in quotes.\n",
        "     |  \n",
        "     |  getPhysicalQuantity(self)\n",
        "     |  \n",
        "     |  get_wunit(self)\n",
        "     |      Return value with unit (dimension) as string, if it has.\n",
        "     |      Otherwise, return value (with the right type).\n",
        "     |  \n",
        "     |  set(self, value)\n",
        "     |      Set the value of the parameter.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from InputPrm:\n",
        "     |  \n",
        "     |  v\n",
        "     |      value of parameter\n",
        "    \n",
        "    class InputPrmGUI(InputPrm)\n",
        "     |  Represent an input parameter by a widget.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, name=None, default=0.0, str2type=None, widget_type='entry', values=None, parent=None, help=None, unit=None, cmlarg=None)\n",
        "     |      @param default:           default value\n",
        "     |      @param str2type:          function from string to type\n",
        "     |      @param name:              name of parameter\n",
        "     |      @param widget_type:       entry, slider, option, checkbutton\n",
        "     |      @param values:            (min,max) interval or options\n",
        "     |      @param parent:            parent widget\n",
        "     |      @param help:              description of parameter\n",
        "     |      @param unit:              physical unit (dimension)\n",
        "     |      @param cmlarg:            command-line argument for sending\n",
        "     |                                this prm to an external program\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |      Application of eval to this output creates the object.\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Get GUI text/number, handle special input like numbers\n",
        "     |      with units, if necessary.\n",
        "     |  \n",
        "     |  get_widget_type(self)\n",
        "     |  \n",
        "     |  make_GUI_variable_Tk(self, str2type, unit, name)\n",
        "     |      Bind self._v to a variable with set and get methods for\n",
        "     |      setting and getting the value in/from a GUI.\n",
        "     |  \n",
        "     |  make_widget(self)\n",
        "     |  \n",
        "     |  make_widget_Tk(self)\n",
        "     |      Make Tk widget according to self._widget_type.\n",
        "     |  \n",
        "     |  set(self, value)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  widget_type\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  GUI_toolkit = 'Tkinter/Pmw'\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from InputPrm:\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |      Compact output; just the value as a formatted string.\n",
        "     |      Note that __str__ is used by __repr__ so strings must\n",
        "     |      be enclosed in quotes.\n",
        "     |  \n",
        "     |  getPhysicalQuantity(self)\n",
        "     |  \n",
        "     |  get_wunit(self)\n",
        "     |      Return value with unit (dimension) as string, if it has.\n",
        "     |      Otherwise, return value (with the right type).\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from InputPrm:\n",
        "     |  \n",
        "     |  v\n",
        "     |      value of parameter\n",
        "    \n",
        "    class Parameters\n",
        "     |  Class for holding a set of InputPrm-type parameters.\n",
        "     |  See src/py/examples/simviz/simviz1cp.py for examples\n",
        "     |  on usage.\n",
        "     |  \n",
        "     |  Some attributes may be useful in application code:\n",
        "     |  \n",
        "     |  self.dict is a dictionary of InputPrm-type objects.\n",
        "     |  \n",
        "     |  self.parameters_sequence (and self._seq) is a list of\n",
        "     |  InputPrm-type objects in the sequence they were registered.\n",
        "     |  \n",
        "     |  self.sliders_sequence is a list of InputPrm-type objects,\n",
        "     |  with slider widget representation in a GUI, in the sequence\n",
        "     |  they were registered.\n",
        "     |  self.entries_sequence, self.checkbt_sequence,\n",
        "     |  self.options_sequence are similar for text entries, checkbuttons,\n",
        "     |  and option menus.\n",
        "     |  \n",
        "     |  The self.*_sequence lists can be used to build GUIs or CGI scripts.\n",
        "     |  Normally, this is automated in classes like AutoSimVizGUI and\n",
        "     |  AutoSimVizCGI.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __getitem__(self, name)\n",
        "     |  \n",
        "     |  __init__(self, interface='plain', form=None, prm_dict={})\n",
        "     |      @param interface: 'plain', 'CGI', or 'GUI'\n",
        "     |      @param form: cgi.FieldStorage() object\n",
        "     |      @param prm_dict: dictionary with (name,value) pairs\n",
        "     |      (will be added using the add method)\n",
        "     |  \n",
        "     |  __iter__(self)\n",
        "     |      Iterate over keys in self.dict.\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __setattr__(self, name, value)\n",
        "     |      If name2attr is called, self.m = 2.3 (using this\n",
        "     |      function) is safe, because this also implies update of\n",
        "     |      the corresponding InputPrm-type object in self.dict.\n",
        "     |  \n",
        "     |  __setitem__(self, name, value)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  add(self, name, default, str2type=None, widget_type='entry', values=None, help=None, unit=None, cmlarg=None)\n",
        "     |      Add a new parameter.\n",
        "     |  \n",
        "     |  dump(self)\n",
        "     |  \n",
        "     |  endadd(self)\n",
        "     |      Process parameters, make internal data structures.\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Return dictionary with (name,value) pairs.\n",
        "     |  \n",
        "     |  keys(self)\n",
        "     |      Return parameter names. With this method Parameter objects p\n",
        "     |      can be used in dictionary update functions: somedict.update(p).\n",
        "     |  \n",
        "     |  name2attr(self)\n",
        "     |      Turn all item keys into attributes.\n",
        "     |      Warning: values are copied! __setitem__ and\n",
        "     |      __setattr__ (or properties) must\n",
        "     |      take care of parallel updates.\n",
        "     |  \n",
        "     |  parse_options(self, argv)\n",
        "     |      Examine the command line and for each -opt val pair,\n",
        "     |      set the value of parameter opt to val, if opt is a\n",
        "     |      registered parameter.\n",
        "     |      argv is typically sys.argv[1:]\n",
        "     |      Note that the name of a parameter may contain blanks.\n",
        "     |      A blank is replaced by two underscores in the command-line\n",
        "     |      options.\n",
        "     |  \n",
        "     |  usage(self)\n",
        "     |      Print legal command-line options.\n",
        "    \n",
        "    class StringFormula\n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, parent, func_spec)\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Return function object.\n",
        "    \n",
        "    class UserFunction\n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, parent, func_spec)\n",
        "     |  \n",
        "     |  get(self)\n",
        "     |      Return function object.\n",
        "\n",
        "FUNCTIONS\n",
        "    commandline2dict(argv, parameters)\n",
        "        Load data from the command line into a dictionary of\n",
        "        parameter values. The argv argument is typically sys.argv[1:].\n",
        "        Each option --opt in argv is extracted and the\n",
        "        proceeding value v is assigned to parameters:\n",
        "           parameters[opt].set(v)\n",
        "        Hence, parameters must hold objects that have a set\n",
        "        function. Normally, parameters is a dictionary of\n",
        "        InputPrm objects.\n",
        "    \n",
        "    createInputPrm(interface, name, default, str2type=None, widget_type='entry', values=None, parent=None, form=None, help=None, unit=None, cmlarg=None)\n",
        "        Unified interface to parameter classes InputPrm/GUI/CGI.\n",
        "    \n",
        "    parametersGUI(p, parent, pack_side='top', scrolled={'height': 400, 'width': 350})\n",
        "        Load all parameters in a Parameters object p into a GUI.\n",
        "        \n",
        "        parent          parent widget\n",
        "        pack_side       packing is donw with\n",
        "                        widget.pack(side=pack_side, expand=1, fill='both')\n",
        "        scrolled        False: use standard Tk Frame\n",
        "                        non-empty dict: use Pmw.ScrolledFrame with the\n",
        "                        prescribed height and width\n",
        "    \n",
        "    points2grid(x, y, xcoor)\n",
        "        Transform points (x,y) to a uniform grid with coordinates xcoor.\n",
        "    \n",
        "    roundInt(a)\n",
        "    \n",
        "    test_FunctionChoices(root)\n",
        "\n",
        "DATA\n",
        "    Pmw = <PmwLoader instance>\n",
        "    pi = 3.141592653589793\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.svm as svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on package sklearn.svm in sklearn:\n",
        "\n",
        "NAME\n",
        "    sklearn.svm - The :mod:`sklearn.svm` module includes Support Vector Machine algorithms.\n",
        "\n",
        "FILE\n",
        "    /usr/lib64/python2.7/site-packages/sklearn/svm/__init__.py\n",
        "\n",
        "PACKAGE CONTENTS\n",
        "    base\n",
        "    bounds\n",
        "    classes\n",
        "    liblinear\n",
        "    libsvm\n",
        "    libsvm_sparse\n",
        "    setup\n",
        "    sparse (package)\n",
        "    tests (package)\n",
        "\n",
        "CLASSES\n",
        "    sklearn.base.RegressorMixin(__builtin__.object)\n",
        "        sklearn.svm.classes.NuSVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
        "        sklearn.svm.classes.SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
        "    sklearn.feature_selection.selector_mixin.SelectorMixin(sklearn.base.TransformerMixin)\n",
        "        sklearn.svm.classes.LinearSVC(sklearn.svm.base.BaseLibLinear, sklearn.linear_model.base.LinearClassifierMixin, sklearn.feature_selection.selector_mixin.SelectorMixin)\n",
        "    sklearn.linear_model.base.LinearClassifierMixin(sklearn.base.ClassifierMixin)\n",
        "        sklearn.svm.classes.LinearSVC(sklearn.svm.base.BaseLibLinear, sklearn.linear_model.base.LinearClassifierMixin, sklearn.feature_selection.selector_mixin.SelectorMixin)\n",
        "    sklearn.svm.base.BaseLibLinear(sklearn.base.BaseEstimator)\n",
        "        sklearn.svm.classes.LinearSVC(sklearn.svm.base.BaseLibLinear, sklearn.linear_model.base.LinearClassifierMixin, sklearn.feature_selection.selector_mixin.SelectorMixin)\n",
        "    sklearn.svm.base.BaseLibSVM(sklearn.base.BaseEstimator)\n",
        "        sklearn.svm.classes.NuSVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
        "        sklearn.svm.classes.OneClassSVM\n",
        "        sklearn.svm.classes.SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
        "    sklearn.svm.base.BaseSVC(sklearn.svm.base.BaseLibSVM, sklearn.base.ClassifierMixin)\n",
        "        sklearn.svm.classes.NuSVC\n",
        "        sklearn.svm.classes.SVC\n",
        "    \n",
        "    class LinearSVC(sklearn.svm.base.BaseLibLinear, sklearn.linear_model.base.LinearClassifierMixin, sklearn.feature_selection.selector_mixin.SelectorMixin)\n",
        "     |  Linear Support Vector Classification.\n",
        "     |  \n",
        "     |  Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
        "     |  liblinear rather than libsvm, so it has more flexibility in the choice of\n",
        "     |  penalties and loss functions and should scale better (to large numbers of\n",
        "     |  samples).\n",
        "     |  \n",
        "     |  This class supports both dense and sparse input and the multiclass support\n",
        "     |  is handled according to a one-vs-the-rest scheme.\n",
        "     |  \n",
        "     |  Parameters\n",
        "     |  ----------\n",
        "     |  C : float, optional (default=1.0)\n",
        "     |      Penalty parameter C of the error term.\n",
        "     |  \n",
        "     |  loss : string, 'l1' or 'l2' (default='l2')\n",
        "     |      Specifies the loss function. 'l1' is the hinge loss (standard SVM)\n",
        "     |      while 'l2' is the squared hinge loss.\n",
        "     |  \n",
        "     |  penalty : string, 'l1' or 'l2' (default='l2')\n",
        "     |      Specifies the norm used in the penalization. The 'l2'\n",
        "     |      penalty is the standard used in SVC. The 'l1' leads to `coef_`\n",
        "     |      vectors that are sparse.\n",
        "     |  \n",
        "     |  dual : bool, (default=True)\n",
        "     |      Select the algorithm to either solve the dual or primal\n",
        "     |      optimization problem. Prefer dual=False when n_samples > n_features.\n",
        "     |  \n",
        "     |  tol : float, optional (default=1e-4)\n",
        "     |      Tolerance for stopping criteria\n",
        "     |  \n",
        "     |  multi_class: string, 'ovr' or 'crammer_singer' (default='ovr')\n",
        "     |      Determines the multi-class strategy if `y` contains more than\n",
        "     |      two classes.\n",
        "     |      `ovr` trains n_classes one-vs-rest classifiers, while `crammer_singer`\n",
        "     |      optimizes a joint objective over all classes.\n",
        "     |      While `crammer_singer` is interesting from an theoretical perspective\n",
        "     |      as it is consistent it is seldom used in practice and rarely leads to\n",
        "     |      better accuracy and is more expensive to compute.\n",
        "     |      If `crammer_singer` is choosen, the options loss, penalty and dual will\n",
        "     |      be ignored.\n",
        "     |  \n",
        "     |  fit_intercept : boolean, optional (default=True)\n",
        "     |      Whether to calculate the intercept for this model. If set\n",
        "     |      to false, no intercept will be used in calculations\n",
        "     |      (e.g. data is expected to be already centered).\n",
        "     |  \n",
        "     |  intercept_scaling : float, optional (default=1)\n",
        "     |      when self.fit_intercept is True, instance vector x becomes\n",
        "     |      [x, self.intercept_scaling],\n",
        "     |      i.e. a \"synthetic\" feature with constant value equals to\n",
        "     |      intercept_scaling is appended to the instance vector.\n",
        "     |      The intercept becomes intercept_scaling * synthetic feature weight\n",
        "     |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
        "     |      as all other features.\n",
        "     |      To lessen the effect of regularization on synthetic feature weight\n",
        "     |      (and therefore on the intercept) intercept_scaling has to be increased\n",
        "     |  \n",
        "     |  class_weight : {dict, 'auto'}, optional\n",
        "     |      Set the parameter C of class i to class_weight[i]*C for\n",
        "     |      SVC. If not given, all classes are supposed to have\n",
        "     |      weight one. The 'auto' mode uses the values of y to\n",
        "     |      automatically adjust weights inversely proportional to\n",
        "     |      class frequencies.\n",
        "     |  \n",
        "     |  verbose : int, default: 0\n",
        "     |      Enable verbose output. Note that this setting takes advantage of a\n",
        "     |      per-process runtime setting in liblinear that, if enabled, may not work\n",
        "     |      properly in a multithreaded context.\n",
        "     |  \n",
        "     |  Attributes\n",
        "     |  ----------\n",
        "     |  `coef_` : array, shape = [n_features] if n_classes == 2             else [n_classes, n_features]\n",
        "     |      Weights asigned to the features (coefficients in the primal\n",
        "     |      problem). This is only available in the case of linear kernel.\n",
        "     |  \n",
        "     |      `coef_` is readonly property derived from `raw_coef_` that         follows the internal memory layout of liblinear.\n",
        "     |  \n",
        "     |  `intercept_` : array, shape = [1] if n_classes == 2 else [n_classes]\n",
        "     |      Constants in decision function.\n",
        "     |  \n",
        "     |  Notes\n",
        "     |  -----\n",
        "     |  The underlying C implementation uses a random number generator to\n",
        "     |  select features when fitting the model. It is thus not uncommon,\n",
        "     |  to have slightly different results for the same input data. If\n",
        "     |  that happens, try with a smaller tol parameter.\n",
        "     |  \n",
        "     |  The underlying implementation (liblinear) uses a sparse internal\n",
        "     |  representation for the data that will incur a memory copy.\n",
        "     |  \n",
        "     |  **References:**\n",
        "     |  `LIBLINEAR: A Library for Large Linear Classification\n",
        "     |  <http://www.csie.ntu.edu.tw/~cjlin/liblinear/>`__\n",
        "     |  \n",
        "     |  See also\n",
        "     |  --------\n",
        "     |  SVC\n",
        "     |      Implementation of Support Vector Machine classifier using libsvm:\n",
        "     |      the kernel can be non-linear but its SMO algorithm does not\n",
        "     |      scale to large number of samples as LinearSVC does.\n",
        "     |  \n",
        "     |      Furthermore SVC multi-class mode is implemented using one\n",
        "     |      vs one scheme while LinearSVC uses one vs the rest. It is\n",
        "     |      possible to implement one vs the rest with SVC by using the\n",
        "     |      :class:`sklearn.multiclass.OneVsRestClassifier` wrapper.\n",
        "     |  \n",
        "     |      Finally SVC can fit dense data without memory copy if the input\n",
        "     |      is C-contiguous. Sparse data will still incur memory copy though.\n",
        "     |  \n",
        "     |  sklearn.linear_model.SGDClassifier\n",
        "     |      SGDClassifier can optimize the same cost function as LinearSVC\n",
        "     |      by adjusting the penalty and loss parameters. Furthermore\n",
        "     |      SGDClassifier is scalable to large number of samples as it uses\n",
        "     |      a Stochastic Gradient Descent optimizer.\n",
        "     |  \n",
        "     |      Finally SGDClassifier can fit both dense and sparse data without\n",
        "     |      memory copy if the input is C-contiguous or CSR.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      LinearSVC\n",
        "     |      sklearn.svm.base.BaseLibLinear\n",
        "     |      sklearn.base.BaseEstimator\n",
        "     |      sklearn.linear_model.base.LinearClassifierMixin\n",
        "     |      sklearn.base.ClassifierMixin\n",
        "     |      sklearn.feature_selection.selector_mixin.SelectorMixin\n",
        "     |      sklearn.base.TransformerMixin\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods inherited from sklearn.svm.base.BaseLibLinear:\n",
        "     |  \n",
        "     |  __init__(self, penalty='l2', loss='l2', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None)\n",
        "     |  \n",
        "     |  fit(self, X, y)\n",
        "     |      Fit the model according to the given training data.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Training vector, where n_samples in the number of samples and\n",
        "     |          n_features is the number of features.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Target vector relative to X\n",
        "     |      \n",
        "     |      class_weight : {dict, 'auto'}, optional\n",
        "     |          Weights associated with classes. If not given, all classes\n",
        "     |          are supposed to have weight one.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self : object\n",
        "     |          Returns self.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseLibLinear:\n",
        "     |  \n",
        "     |  classes_\n",
        "     |  \n",
        "     |  label_\n",
        "     |      DEPRECATED: The ``label_`` attribute has been renamed to ``classes_`` for consistency and will be removed in 0.15.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  get_params(self, deep=True)\n",
        "     |      Get parameters for the estimator\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      deep: boolean, optional\n",
        "     |          If True, will return the parameters for this estimator and\n",
        "     |          contained subobjects that are estimators.\n",
        "     |  \n",
        "     |  set_params(self, **params)\n",
        "     |      Set the parameters of the estimator.\n",
        "     |      \n",
        "     |      The method works on simple estimators as well as on nested objects\n",
        "     |      (such as pipelines). The former have parameters of the form\n",
        "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
        "     |      component of a nested object.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
        "     |  \n",
        "     |  decision_function(self, X)\n",
        "     |      Predict confidence scores for samples.\n",
        "     |      \n",
        "     |      The confidence score for a sample is the signed distance of that\n",
        "     |      sample to the hyperplane.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Samples.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      array, shape = [n_samples] if n_classes == 2 else [n_samples,n_classes]\n",
        "     |          Confidence scores per (sample, class) combination. In the binary\n",
        "     |          case, confidence score for the \"positive\" class.\n",
        "     |  \n",
        "     |  predict(self, X)\n",
        "     |      Predict class labels for samples in X.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Samples.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      C : array, shape = [n_samples]\n",
        "     |          Predicted class label per sample.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
        "     |  \n",
        "     |  score(self, X, y)\n",
        "     |      Returns the mean accuracy on the given test data and labels.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |          Training set.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Labels for X.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      z : float\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.feature_selection.selector_mixin.SelectorMixin:\n",
        "     |  \n",
        "     |  transform(self, X, threshold=None)\n",
        "     |      Reduce X to its most important features.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array or scipy sparse matrix of shape [n_samples, n_features]\n",
        "     |          The input samples.\n",
        "     |      \n",
        "     |      threshold : string, float or None, optional (default=None)\n",
        "     |          The threshold value to use for feature selection. Features whose\n",
        "     |          importance is greater or equal are kept while the others are\n",
        "     |          discarded. If \"median\" (resp. \"mean\"), then the threshold value is\n",
        "     |          the median (resp. the mean) of the feature importances. A scaling\n",
        "     |          factor (e.g., \"1.25*mean\") may also be used. If None and if\n",
        "     |          available, the object attribute ``threshold`` is used. Otherwise,\n",
        "     |          \"mean\" is used by default.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X_r : array of shape [n_samples, n_selected_features]\n",
        "     |          The input samples with only the selected features.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
        "     |  \n",
        "     |  fit_transform(self, X, y=None, **fit_params)\n",
        "     |      Fit to data, then transform it\n",
        "     |      \n",
        "     |      Fits transformer to X and y with optional parameters fit_params\n",
        "     |      and returns a transformed version of X.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : numpy array of shape [n_samples, n_features]\n",
        "     |          Training set.\n",
        "     |      \n",
        "     |      y : numpy array of shape [n_samples]\n",
        "     |          Target values.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X_new : numpy array of shape [n_samples, n_features_new]\n",
        "     |          Transformed array.\n",
        "    \n",
        "    class NuSVC(sklearn.svm.base.BaseSVC)\n",
        "     |  Nu-Support Vector Classification.\n",
        "     |  \n",
        "     |  Similar to SVC but uses a parameter to control the number of support\n",
        "     |  vectors.\n",
        "     |  \n",
        "     |  The implementation is based on libsvm.\n",
        "     |  \n",
        "     |  Parameters\n",
        "     |  ----------\n",
        "     |  nu : float, optional (default=0.5)\n",
        "     |      An upper bound on the fraction of training errors and a lower\n",
        "     |      bound of the fraction of support vectors. Should be in the\n",
        "     |      interval (0, 1].\n",
        "     |  \n",
        "     |  kernel : string, optional (default='rbf')\n",
        "     |       Specifies the kernel type to be used in the algorithm.\n",
        "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
        "     |       a callable.\n",
        "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
        "     |       used to precompute the kernel matrix.\n",
        "     |  \n",
        "     |  degree : int, optional (default=3)\n",
        "     |      degree of kernel function\n",
        "     |      is significant only in poly, rbf, sigmoid\n",
        "     |  \n",
        "     |  gamma : float, optional (default=0.0)\n",
        "     |      kernel coefficient for rbf and poly, if gamma is 0.0 then 1/n_features\n",
        "     |      will be taken.\n",
        "     |  \n",
        "     |  coef0 : float, optional (default=0.0)\n",
        "     |      independent term in kernel function. It is only significant\n",
        "     |      in poly/sigmoid.\n",
        "     |  \n",
        "     |  probability: boolean, optional (default=False)\n",
        "     |      Whether to enable probability estimates. This must be enabled prior\n",
        "     |      to calling predict_proba.\n",
        "     |  \n",
        "     |  shrinking: boolean, optional (default=True)\n",
        "     |      Whether to use the shrinking heuristic.\n",
        "     |  \n",
        "     |  tol : float, optional (default=1e-3)\n",
        "     |      Tolerance for stopping criterion.\n",
        "     |  \n",
        "     |  cache_size : float, optional\n",
        "     |      Specify the size of the kernel cache (in MB)\n",
        "     |  \n",
        "     |  verbose : bool, default: False\n",
        "     |      Enable verbose output. Note that this setting takes advantage of a\n",
        "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
        "     |      properly in a multithreaded context.\n",
        "     |  \n",
        "     |  max_iter : int, optional (default=-1)\n",
        "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
        "     |  \n",
        "     |  Attributes\n",
        "     |  ----------\n",
        "     |  `support_` : array-like, shape = [n_SV]\n",
        "     |      Index of support vectors.\n",
        "     |  \n",
        "     |  `support_vectors_` : array-like, shape = [n_SV, n_features]\n",
        "     |      Support vectors.\n",
        "     |  \n",
        "     |  `n_support_` : array-like, dtype=int32, shape = [n_class]\n",
        "     |      number of support vector for each class.\n",
        "     |  \n",
        "     |  `dual_coef_` : array, shape = [n_class-1, n_SV]\n",
        "     |      Coefficients of the support vector in the decision function.         For multiclass, coefficient for all 1-vs-1 classifiers.         The layout of the coefficients in the multiclass case is somewhat         non-trivial. See the section about multi-class classification in         the SVM section of the User Guide for details.\n",
        "     |  \n",
        "     |  `coef_` : array, shape = [n_class-1, n_features]\n",
        "     |      Weights asigned to the features (coefficients in the primal\n",
        "     |      problem). This is only available in the case of linear kernel.\n",
        "     |  \n",
        "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
        "     |      `support_vectors_`\n",
        "     |  \n",
        "     |  `intercept_` : array, shape = [n_class * (n_class-1) / 2]\n",
        "     |      Constants in decision function.\n",
        "     |  \n",
        "     |  Examples\n",
        "     |  --------\n",
        "     |  >>> import numpy as np\n",
        "     |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
        "     |  >>> y = np.array([1, 1, 2, 2])\n",
        "     |  >>> from sklearn.svm import NuSVC\n",
        "     |  >>> clf = NuSVC()\n",
        "     |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
        "     |  NuSVC(cache_size=200, coef0=0.0, degree=3, gamma=0.0, kernel='rbf',\n",
        "     |          max_iter=-1, nu=0.5, probability=False, shrinking=True, tol=0.001,\n",
        "     |          verbose=False)\n",
        "     |  >>> print(clf.predict([[-0.8, -1]]))\n",
        "     |  [1]\n",
        "     |  \n",
        "     |  See also\n",
        "     |  --------\n",
        "     |  SVC\n",
        "     |      Support Vector Machine for classification using libsvm.\n",
        "     |  \n",
        "     |  LinearSVC\n",
        "     |      Scalable linear Support Vector Machine for classification using\n",
        "     |      liblinear.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      NuSVC\n",
        "     |      sklearn.svm.base.BaseSVC\n",
        "     |      sklearn.svm.base.BaseLibSVM\n",
        "     |      sklearn.base.BaseEstimator\n",
        "     |      sklearn.base.ClassifierMixin\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, nu=0.5, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, verbose=False, max_iter=-1)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  __abstractmethods__ = frozenset([])\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
        "     |  \n",
        "     |  predict(self, X)\n",
        "     |      Perform classification on samples in X.\n",
        "     |      \n",
        "     |      For an one-class model, +1 or -1 is returned.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      y_pred : array, shape = [n_samples]\n",
        "     |          Class labels for samples in X.\n",
        "     |  \n",
        "     |  predict_log_proba(self, X)\n",
        "     |      Compute log probabilities of possible outcomes for samples in X.\n",
        "     |      \n",
        "     |      The model need to have probability information computed at training\n",
        "     |      time: fit with attribute `probability` set to True.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_classes]\n",
        "     |          Returns the log-probabilities of the sample for each class in\n",
        "     |          the model, where classes are ordered by arithmetical\n",
        "     |          order.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      -----\n",
        "     |      The probability model is created using cross validation, so\n",
        "     |      the results can be slightly different than those obtained by\n",
        "     |      predict. Also, it will produce meaningless results on very small\n",
        "     |      datasets.\n",
        "     |  \n",
        "     |  predict_proba(self, X)\n",
        "     |      Compute probabilities of possible outcomes for samples in X.\n",
        "     |      \n",
        "     |      The model need to have probability information computed at training\n",
        "     |      time: fit with attribute `probability` set to True.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_classes]\n",
        "     |          Returns the probability of the sample for each class in\n",
        "     |          the model, where classes are ordered by arithmetical\n",
        "     |          order.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      -----\n",
        "     |      The probability model is created using cross validation, so\n",
        "     |      the results can be slightly different than those obtained by\n",
        "     |      predict. Also, it will produce meaningless results on very small\n",
        "     |      datasets.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
        "     |  \n",
        "     |  label_\n",
        "     |      DEPRECATED: The ``label_`` attribute has been renamed to ``classes_`` for consistency and will be removed in 0.15.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  decision_function(self, X)\n",
        "     |      Distance of the samples X to the separating hyperplane.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_class * (n_class-1) / 2]\n",
        "     |          Returns the decision function of the sample for each class\n",
        "     |          in the model.\n",
        "     |  \n",
        "     |  fit(self, X, y, sample_weight=None)\n",
        "     |      Fit the SVM model according to the given training data.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Training vectors, where n_samples is the number of samples\n",
        "     |          and n_features is the number of features.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Target values (class labels in classification, real numbers in\n",
        "     |          regression)\n",
        "     |      \n",
        "     |      sample_weight : array-like, shape = [n_samples], optional\n",
        "     |          Weights applied to individual samples (1. for unweighted).\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self : object\n",
        "     |          Returns self.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      ------\n",
        "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
        "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
        "     |      \n",
        "     |      If X is a dense array, then the other methods will not support sparse\n",
        "     |      matrices as input.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  coef_\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
        "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
        "     |      \n",
        "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
        "     |      directly, and then acts as a mix-in class.  You can also register\n",
        "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
        "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
        "     |      be considered subclasses of the registering ABC by the built-in\n",
        "     |      issubclass() function, but the registering ABC won't show up in\n",
        "     |      their MRO (Method Resolution Order) nor will method\n",
        "     |      implementations defined by the registering ABC be callable (not\n",
        "     |      even via super()).\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  get_params(self, deep=True)\n",
        "     |      Get parameters for the estimator\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      deep: boolean, optional\n",
        "     |          If True, will return the parameters for this estimator and\n",
        "     |          contained subobjects that are estimators.\n",
        "     |  \n",
        "     |  set_params(self, **params)\n",
        "     |      Set the parameters of the estimator.\n",
        "     |      \n",
        "     |      The method works on simple estimators as well as on nested objects\n",
        "     |      (such as pipelines). The former have parameters of the form\n",
        "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
        "     |      component of a nested object.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
        "     |  \n",
        "     |  score(self, X, y)\n",
        "     |      Returns the mean accuracy on the given test data and labels.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |          Training set.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Labels for X.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      z : float\n",
        "    \n",
        "    class NuSVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
        "     |  Nu Support Vector Regression.\n",
        "     |  \n",
        "     |  Similar to NuSVC, for regression, uses a parameter nu to control\n",
        "     |  the number of support vectors. However, unlike NuSVC, where nu\n",
        "     |  replaces C, here nu replaces with the parameter epsilon of SVR.\n",
        "     |  \n",
        "     |  The implementations is a based on libsvm.\n",
        "     |  \n",
        "     |  Parameters\n",
        "     |  ----------\n",
        "     |  C : float, optional (default=1.0)\n",
        "     |      penalty parameter C of the error term.\n",
        "     |  \n",
        "     |  nu : float, optional\n",
        "     |      An upper bound on the fraction of training errors and a lower bound of\n",
        "     |      the fraction of support vectors. Should be in the interval (0, 1].  By\n",
        "     |      default 0.5 will be taken.  Only available if impl='nu_svc'.\n",
        "     |  \n",
        "     |  kernel : string, optional (default='rbf')\n",
        "     |       Specifies the kernel type to be used in the algorithm.\n",
        "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
        "     |       a callable.\n",
        "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
        "     |       used to precompute the kernel matrix.\n",
        "     |  \n",
        "     |  degree : int, optional (default=3)\n",
        "     |      degree of kernel function\n",
        "     |      is significant only in poly, rbf, sigmoid\n",
        "     |  \n",
        "     |  gamma : float, optional (default=0.0)\n",
        "     |      kernel coefficient for rbf and poly, if gamma is 0.0 then 1/n_features\n",
        "     |      will be taken.\n",
        "     |  \n",
        "     |  coef0 : float, optional (default=0.0)\n",
        "     |      independent term in kernel function. It is only significant\n",
        "     |      in poly/sigmoid.\n",
        "     |  \n",
        "     |  probability: boolean, optional (default=False)\n",
        "     |      Whether to enable probability estimates. This must be enabled prior\n",
        "     |      to calling predict_proba.\n",
        "     |  \n",
        "     |  shrinking: boolean, optional (default=True)\n",
        "     |      Whether to use the shrinking heuristic.\n",
        "     |  \n",
        "     |  tol : float, optional (default=1e-3)\n",
        "     |      Tolerance for stopping criterion.\n",
        "     |  \n",
        "     |  cache_size : float, optional\n",
        "     |      Specify the size of the kernel cache (in MB)\n",
        "     |  \n",
        "     |  verbose : bool, default: False\n",
        "     |      Enable verbose output. Note that this setting takes advantage of a\n",
        "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
        "     |      properly in a multithreaded context.\n",
        "     |  \n",
        "     |  max_iter : int, optional (default=-1)\n",
        "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
        "     |  \n",
        "     |  Attributes\n",
        "     |  ----------\n",
        "     |  `support_` : array-like, shape = [n_SV]\n",
        "     |      Index of support vectors.\n",
        "     |  \n",
        "     |  `support_vectors_` : array-like, shape = [nSV, n_features]\n",
        "     |      Support vectors.\n",
        "     |  \n",
        "     |  `dual_coef_` : array, shape = [n_classes-1, n_SV]\n",
        "     |      Coefficients of the support vector in the decision function.\n",
        "     |  \n",
        "     |  `coef_` : array, shape = [n_classes-1, n_features]\n",
        "     |      Weights asigned to the features (coefficients in the primal\n",
        "     |      problem). This is only available in the case of linear kernel.\n",
        "     |  \n",
        "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
        "     |      `support_vectors_`\n",
        "     |  \n",
        "     |  `intercept_` : array, shape = [n_class * (n_class-1) / 2]\n",
        "     |      Constants in decision function.\n",
        "     |  \n",
        "     |  Examples\n",
        "     |  --------\n",
        "     |  >>> from sklearn.svm import NuSVR\n",
        "     |  >>> import numpy as np\n",
        "     |  >>> n_samples, n_features = 10, 5\n",
        "     |  >>> np.random.seed(0)\n",
        "     |  >>> y = np.random.randn(n_samples)\n",
        "     |  >>> X = np.random.randn(n_samples, n_features)\n",
        "     |  >>> clf = NuSVR(C=1.0, nu=0.1)\n",
        "     |  >>> clf.fit(X, y)  #doctest: +NORMALIZE_WHITESPACE\n",
        "     |  NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma=0.0, kernel='rbf',\n",
        "     |     max_iter=-1, nu=0.1, probability=False, shrinking=True, tol=0.001,\n",
        "     |     verbose=False)\n",
        "     |  \n",
        "     |  See also\n",
        "     |  --------\n",
        "     |  NuSVC\n",
        "     |      Support Vector Machine for classification implemented with libsvm\n",
        "     |      with a parameter to control the number of support vectors.\n",
        "     |  \n",
        "     |  SVR\n",
        "     |      epsilon Support Vector Machine for regression implemented with libsvm.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      NuSVR\n",
        "     |      sklearn.svm.base.BaseLibSVM\n",
        "     |      sklearn.base.BaseEstimator\n",
        "     |      sklearn.base.RegressorMixin\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, nu=0.5, C=1.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, verbose=False, max_iter=-1)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  __abstractmethods__ = frozenset([])\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  decision_function(self, X)\n",
        "     |      Distance of the samples X to the separating hyperplane.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_class * (n_class-1) / 2]\n",
        "     |          Returns the decision function of the sample for each class\n",
        "     |          in the model.\n",
        "     |  \n",
        "     |  fit(self, X, y, sample_weight=None)\n",
        "     |      Fit the SVM model according to the given training data.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Training vectors, where n_samples is the number of samples\n",
        "     |          and n_features is the number of features.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Target values (class labels in classification, real numbers in\n",
        "     |          regression)\n",
        "     |      \n",
        "     |      sample_weight : array-like, shape = [n_samples], optional\n",
        "     |          Weights applied to individual samples (1. for unweighted).\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self : object\n",
        "     |          Returns self.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      ------\n",
        "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
        "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
        "     |      \n",
        "     |      If X is a dense array, then the other methods will not support sparse\n",
        "     |      matrices as input.\n",
        "     |  \n",
        "     |  predict(self, X)\n",
        "     |      Perform regression on samples in X.\n",
        "     |      \n",
        "     |      For an one-class model, +1 or -1 is returned.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      y_pred : array, shape = [n_samples]\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  coef_\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
        "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
        "     |      \n",
        "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
        "     |      directly, and then acts as a mix-in class.  You can also register\n",
        "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
        "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
        "     |      be considered subclasses of the registering ABC by the built-in\n",
        "     |      issubclass() function, but the registering ABC won't show up in\n",
        "     |      their MRO (Method Resolution Order) nor will method\n",
        "     |      implementations defined by the registering ABC be callable (not\n",
        "     |      even via super()).\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  get_params(self, deep=True)\n",
        "     |      Get parameters for the estimator\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      deep: boolean, optional\n",
        "     |          If True, will return the parameters for this estimator and\n",
        "     |          contained subobjects that are estimators.\n",
        "     |  \n",
        "     |  set_params(self, **params)\n",
        "     |      Set the parameters of the estimator.\n",
        "     |      \n",
        "     |      The method works on simple estimators as well as on nested objects\n",
        "     |      (such as pipelines). The former have parameters of the form\n",
        "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
        "     |      component of a nested object.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
        "     |  \n",
        "     |  score(self, X, y)\n",
        "     |      Returns the coefficient of determination R^2 of the prediction.\n",
        "     |      \n",
        "     |      The coefficient R^2 is defined as (1 - u/v), where u is the regression\n",
        "     |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual\n",
        "     |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
        "     |      Best possible score is 1.0, lower values are worse.\n",
        "     |      \n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |          Training set.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      z : float\n",
        "    \n",
        "    class OneClassSVM(sklearn.svm.base.BaseLibSVM)\n",
        "     |  Unsupervised Outliers Detection.\n",
        "     |  \n",
        "     |  Estimate the support of a high-dimensional distribution.\n",
        "     |  \n",
        "     |  The implementation is based on libsvm.\n",
        "     |  \n",
        "     |  Parameters\n",
        "     |  ----------\n",
        "     |  kernel : string, optional (default='rbf')\n",
        "     |       Specifies the kernel type to be used in the algorithm.\n",
        "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
        "     |       a callable.\n",
        "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
        "     |       used to precompute the kernel matrix.\n",
        "     |  \n",
        "     |  nu : float, optional\n",
        "     |      An upper bound on the fraction of training\n",
        "     |      errors and a lower bound of the fraction of support\n",
        "     |      vectors. Should be in the interval (0, 1]. By default 0.5\n",
        "     |      will be taken.\n",
        "     |  \n",
        "     |  degree : int, optional\n",
        "     |      Degree of kernel function. Significant only in poly, rbf, sigmoid.\n",
        "     |  \n",
        "     |  gamma : float, optional (default=0.0)\n",
        "     |      kernel coefficient for rbf and poly, if gamma is 0.0 then 1/n_features\n",
        "     |      will be taken.\n",
        "     |  \n",
        "     |  coef0 : float, optional\n",
        "     |      Independent term in kernel function. It is only significant in\n",
        "     |      poly/sigmoid.\n",
        "     |  \n",
        "     |  tol : float, optional\n",
        "     |      Tolerance for stopping criterion.\n",
        "     |  \n",
        "     |  shrinking: boolean, optional\n",
        "     |      Whether to use the shrinking heuristic.\n",
        "     |  \n",
        "     |  cache_size : float, optional\n",
        "     |      Specify the size of the kernel cache (in MB)\n",
        "     |  \n",
        "     |  verbose : bool, default: False\n",
        "     |      Enable verbose output. Note that this setting takes advantage of a\n",
        "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
        "     |      properly in a multithreaded context.\n",
        "     |  \n",
        "     |  max_iter : int, optional (default=-1)\n",
        "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
        "     |  \n",
        "     |  Attributes\n",
        "     |  ----------\n",
        "     |  `support_` : array-like, shape = [n_SV]\n",
        "     |      Index of support vectors.\n",
        "     |  \n",
        "     |  `support_vectors_` : array-like, shape = [nSV, n_features]\n",
        "     |      Support vectors.\n",
        "     |  \n",
        "     |  `dual_coef_` : array, shape = [n_classes-1, n_SV]\n",
        "     |      Coefficient of the support vector in the decision function.\n",
        "     |  \n",
        "     |  `coef_` : array, shape = [n_classes-1, n_features]\n",
        "     |      Weights asigned to the features (coefficients in the primal\n",
        "     |      problem). This is only available in the case of linear kernel.\n",
        "     |  \n",
        "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
        "     |      `support_vectors_`\n",
        "     |  \n",
        "     |  `intercept_` : array, shape = [n_classes-1]\n",
        "     |      Constants in decision function.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      OneClassSVM\n",
        "     |      sklearn.svm.base.BaseLibSVM\n",
        "     |      sklearn.base.BaseEstimator\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, tol=0.001, nu=0.5, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
        "     |  \n",
        "     |  fit(self, X, sample_weight=None, **params)\n",
        "     |      Detects the soft boundary of the set of samples X.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Set of samples, where n_samples is the number of samples and\n",
        "     |          n_features is the number of features.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self : object\n",
        "     |          Returns self.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      -----\n",
        "     |      If X is not a C-ordered contiguous array it is copied.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  __abstractmethods__ = frozenset([])\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  decision_function(self, X)\n",
        "     |      Distance of the samples X to the separating hyperplane.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_class * (n_class-1) / 2]\n",
        "     |          Returns the decision function of the sample for each class\n",
        "     |          in the model.\n",
        "     |  \n",
        "     |  predict(self, X)\n",
        "     |      Perform regression on samples in X.\n",
        "     |      \n",
        "     |      For an one-class model, +1 or -1 is returned.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      y_pred : array, shape = [n_samples]\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  coef_\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
        "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
        "     |      \n",
        "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
        "     |      directly, and then acts as a mix-in class.  You can also register\n",
        "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
        "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
        "     |      be considered subclasses of the registering ABC by the built-in\n",
        "     |      issubclass() function, but the registering ABC won't show up in\n",
        "     |      their MRO (Method Resolution Order) nor will method\n",
        "     |      implementations defined by the registering ABC be callable (not\n",
        "     |      even via super()).\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  get_params(self, deep=True)\n",
        "     |      Get parameters for the estimator\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      deep: boolean, optional\n",
        "     |          If True, will return the parameters for this estimator and\n",
        "     |          contained subobjects that are estimators.\n",
        "     |  \n",
        "     |  set_params(self, **params)\n",
        "     |      Set the parameters of the estimator.\n",
        "     |      \n",
        "     |      The method works on simple estimators as well as on nested objects\n",
        "     |      (such as pipelines). The former have parameters of the form\n",
        "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
        "     |      component of a nested object.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "    \n",
        "    class SVC(sklearn.svm.base.BaseSVC)\n",
        "     |  C-Support Vector Classification.\n",
        "     |  \n",
        "     |  The implementations is a based on libsvm. The fit time complexity\n",
        "     |  is more than quadratic with the number of samples which makes it hard\n",
        "     |  to scale to dataset with more than a couple of 10000 samples.\n",
        "     |  \n",
        "     |  The multiclass support is handled according to a one-vs-one scheme.\n",
        "     |  \n",
        "     |  For details on the precise mathematical formulation of the provided\n",
        "     |  kernel functions and how `gamma`, `coef0` and `degree` affect each,\n",
        "     |  see the corresponding section in the narrative documentation:\n",
        "     |  :ref:`svm_kernels`.\n",
        "     |  \n",
        "     |  .. The narrative documentation is available at http://scikit-learn.org/\n",
        "     |  \n",
        "     |  Parameters\n",
        "     |  ----------\n",
        "     |  C : float, optional (default=1.0)\n",
        "     |      Penalty parameter C of the error term.\n",
        "     |  \n",
        "     |  kernel : string, optional (default='rbf')\n",
        "     |       Specifies the kernel type to be used in the algorithm.\n",
        "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
        "     |       a callable.\n",
        "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
        "     |       used to precompute the kernel matrix.\n",
        "     |  \n",
        "     |  degree : int, optional (default=3)\n",
        "     |      Degree of kernel function.\n",
        "     |      It is significant only in 'poly' and 'sigmoid'.\n",
        "     |  \n",
        "     |  gamma : float, optional (default=0.0)\n",
        "     |      Kernel coefficient for 'rbf' and 'poly'.\n",
        "     |      If gamma is 0.0 then 1/n_features will be used instead.\n",
        "     |  \n",
        "     |  coef0 : float, optional (default=0.0)\n",
        "     |      Independent term in kernel function.\n",
        "     |      It is only significant in 'poly' and 'sigmoid'.\n",
        "     |  \n",
        "     |  probability: boolean, optional (default=False)\n",
        "     |      Whether to enable probability estimates. This must be enabled prior\n",
        "     |      to calling predict_proba.\n",
        "     |  \n",
        "     |  shrinking: boolean, optional (default=True)\n",
        "     |      Whether to use the shrinking heuristic.\n",
        "     |  \n",
        "     |  tol : float, optional (default=1e-3)\n",
        "     |      Tolerance for stopping criterion.\n",
        "     |  \n",
        "     |  cache_size : float, optional\n",
        "     |      Specify the size of the kernel cache (in MB)\n",
        "     |  \n",
        "     |  class_weight : {dict, 'auto'}, optional\n",
        "     |      Set the parameter C of class i to class_weight[i]*C for\n",
        "     |      SVC. If not given, all classes are supposed to have\n",
        "     |      weight one. The 'auto' mode uses the values of y to\n",
        "     |      automatically adjust weights inversely proportional to\n",
        "     |      class frequencies.\n",
        "     |  \n",
        "     |  verbose : bool, default: False\n",
        "     |      Enable verbose output. Note that this setting takes advantage of a\n",
        "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
        "     |      properly in a multithreaded context.\n",
        "     |  \n",
        "     |  max_iter : int, optional (default=-1)\n",
        "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
        "     |  \n",
        "     |  Attributes\n",
        "     |  ----------\n",
        "     |  `support_` : array-like, shape = [n_SV]\n",
        "     |      Index of support vectors.\n",
        "     |  \n",
        "     |  `support_vectors_` : array-like, shape = [n_SV, n_features]\n",
        "     |      Support vectors.\n",
        "     |  \n",
        "     |  `n_support_` : array-like, dtype=int32, shape = [n_class]\n",
        "     |      number of support vector for each class.\n",
        "     |  \n",
        "     |  `dual_coef_` : array, shape = [n_class-1, n_SV]\n",
        "     |      Coefficients of the support vector in the decision function.         For multiclass, coefficient for all 1-vs-1 classifiers.         The layout of the coefficients in the multiclass case is somewhat         non-trivial. See the section about multi-class classification in the         SVM section of the User Guide for details.\n",
        "     |  \n",
        "     |  `coef_` : array, shape = [n_class-1, n_features]\n",
        "     |      Weights asigned to the features (coefficients in the primal\n",
        "     |      problem). This is only available in the case of linear kernel.\n",
        "     |  \n",
        "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
        "     |      `support_vectors_`\n",
        "     |  \n",
        "     |  `intercept_` : array, shape = [n_class * (n_class-1) / 2]\n",
        "     |      Constants in decision function.\n",
        "     |  \n",
        "     |  Examples\n",
        "     |  --------\n",
        "     |  >>> import numpy as np\n",
        "     |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
        "     |  >>> y = np.array([1, 1, 2, 2])\n",
        "     |  >>> from sklearn.svm import SVC\n",
        "     |  >>> clf = SVC()\n",
        "     |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
        "     |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
        "     |          gamma=0.0, kernel='rbf', max_iter=-1, probability=False,\n",
        "     |          shrinking=True, tol=0.001, verbose=False)\n",
        "     |  >>> print(clf.predict([[-0.8, -1]]))\n",
        "     |  [1]\n",
        "     |  \n",
        "     |  See also\n",
        "     |  --------\n",
        "     |  SVR\n",
        "     |      Support Vector Machine for Regression implemented using libsvm.\n",
        "     |  \n",
        "     |  LinearSVC\n",
        "     |      Scalable Linear Support Vector Machine for classififcation\n",
        "     |      implemented using liblinear. Check the See also section of\n",
        "     |      LinearSVC for more comparison element.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      SVC\n",
        "     |      sklearn.svm.base.BaseSVC\n",
        "     |      sklearn.svm.base.BaseLibSVM\n",
        "     |      sklearn.base.BaseEstimator\n",
        "     |      sklearn.base.ClassifierMixin\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  __abstractmethods__ = frozenset([])\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
        "     |  \n",
        "     |  predict(self, X)\n",
        "     |      Perform classification on samples in X.\n",
        "     |      \n",
        "     |      For an one-class model, +1 or -1 is returned.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      y_pred : array, shape = [n_samples]\n",
        "     |          Class labels for samples in X.\n",
        "     |  \n",
        "     |  predict_log_proba(self, X)\n",
        "     |      Compute log probabilities of possible outcomes for samples in X.\n",
        "     |      \n",
        "     |      The model need to have probability information computed at training\n",
        "     |      time: fit with attribute `probability` set to True.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_classes]\n",
        "     |          Returns the log-probabilities of the sample for each class in\n",
        "     |          the model, where classes are ordered by arithmetical\n",
        "     |          order.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      -----\n",
        "     |      The probability model is created using cross validation, so\n",
        "     |      the results can be slightly different than those obtained by\n",
        "     |      predict. Also, it will produce meaningless results on very small\n",
        "     |      datasets.\n",
        "     |  \n",
        "     |  predict_proba(self, X)\n",
        "     |      Compute probabilities of possible outcomes for samples in X.\n",
        "     |      \n",
        "     |      The model need to have probability information computed at training\n",
        "     |      time: fit with attribute `probability` set to True.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_classes]\n",
        "     |          Returns the probability of the sample for each class in\n",
        "     |          the model, where classes are ordered by arithmetical\n",
        "     |          order.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      -----\n",
        "     |      The probability model is created using cross validation, so\n",
        "     |      the results can be slightly different than those obtained by\n",
        "     |      predict. Also, it will produce meaningless results on very small\n",
        "     |      datasets.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
        "     |  \n",
        "     |  label_\n",
        "     |      DEPRECATED: The ``label_`` attribute has been renamed to ``classes_`` for consistency and will be removed in 0.15.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  decision_function(self, X)\n",
        "     |      Distance of the samples X to the separating hyperplane.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_class * (n_class-1) / 2]\n",
        "     |          Returns the decision function of the sample for each class\n",
        "     |          in the model.\n",
        "     |  \n",
        "     |  fit(self, X, y, sample_weight=None)\n",
        "     |      Fit the SVM model according to the given training data.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Training vectors, where n_samples is the number of samples\n",
        "     |          and n_features is the number of features.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Target values (class labels in classification, real numbers in\n",
        "     |          regression)\n",
        "     |      \n",
        "     |      sample_weight : array-like, shape = [n_samples], optional\n",
        "     |          Weights applied to individual samples (1. for unweighted).\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self : object\n",
        "     |          Returns self.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      ------\n",
        "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
        "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
        "     |      \n",
        "     |      If X is a dense array, then the other methods will not support sparse\n",
        "     |      matrices as input.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  coef_\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
        "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
        "     |      \n",
        "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
        "     |      directly, and then acts as a mix-in class.  You can also register\n",
        "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
        "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
        "     |      be considered subclasses of the registering ABC by the built-in\n",
        "     |      issubclass() function, but the registering ABC won't show up in\n",
        "     |      their MRO (Method Resolution Order) nor will method\n",
        "     |      implementations defined by the registering ABC be callable (not\n",
        "     |      even via super()).\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  get_params(self, deep=True)\n",
        "     |      Get parameters for the estimator\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      deep: boolean, optional\n",
        "     |          If True, will return the parameters for this estimator and\n",
        "     |          contained subobjects that are estimators.\n",
        "     |  \n",
        "     |  set_params(self, **params)\n",
        "     |      Set the parameters of the estimator.\n",
        "     |      \n",
        "     |      The method works on simple estimators as well as on nested objects\n",
        "     |      (such as pipelines). The former have parameters of the form\n",
        "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
        "     |      component of a nested object.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
        "     |  \n",
        "     |  score(self, X, y)\n",
        "     |      Returns the mean accuracy on the given test data and labels.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |          Training set.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Labels for X.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      z : float\n",
        "    \n",
        "    class SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
        "     |  epsilon-Support Vector Regression.\n",
        "     |  \n",
        "     |  The free parameters in the model are C and epsilon.\n",
        "     |  \n",
        "     |  The implementations is a based on libsvm.\n",
        "     |  \n",
        "     |  Parameters\n",
        "     |  ----------\n",
        "     |  C : float, optional (default=1.0)\n",
        "     |      penalty parameter C of the error term.\n",
        "     |  \n",
        "     |  epsilon : float, optional (default=0.1)\n",
        "     |       epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
        "     |       within which no penalty is associated in the training loss function\n",
        "     |       with points predicted within a distance epsilon from the actual\n",
        "     |       value.\n",
        "     |  \n",
        "     |  kernel : string, optional (default='rbf')\n",
        "     |       Specifies the kernel type to be used in the algorithm.\n",
        "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
        "     |       a callable.\n",
        "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
        "     |       used to precompute the kernel matrix.\n",
        "     |  \n",
        "     |  degree : int, optional (default=3)\n",
        "     |      degree of kernel function\n",
        "     |      is significant only in poly, rbf, sigmoid\n",
        "     |  \n",
        "     |  gamma : float, optional (default=0.0)\n",
        "     |      kernel coefficient for rbf and poly, if gamma is 0.0 then 1/n_features\n",
        "     |      will be taken.\n",
        "     |  \n",
        "     |  coef0 : float, optional (default=0.0)\n",
        "     |      independent term in kernel function. It is only significant\n",
        "     |      in poly/sigmoid.\n",
        "     |  \n",
        "     |  probability: boolean, optional (default=False)\n",
        "     |      Whether to enable probability estimates. This must be enabled prior\n",
        "     |      to calling predict_proba.\n",
        "     |  \n",
        "     |  shrinking: boolean, optional (default=True)\n",
        "     |      Whether to use the shrinking heuristic.\n",
        "     |  \n",
        "     |  tol : float, optional (default=1e-3)\n",
        "     |      Tolerance for stopping criterion.\n",
        "     |  \n",
        "     |  cache_size : float, optional\n",
        "     |      Specify the size of the kernel cache (in MB)\n",
        "     |  \n",
        "     |  verbose : bool, default: False\n",
        "     |      Enable verbose output. Note that this setting takes advantage of a\n",
        "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
        "     |      properly in a multithreaded context.\n",
        "     |  \n",
        "     |  max_iter : int, optional (default=-1)\n",
        "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
        "     |  \n",
        "     |  Attributes\n",
        "     |  ----------\n",
        "     |  `support_` : array-like, shape = [n_SV]\n",
        "     |      Index of support vectors.\n",
        "     |  \n",
        "     |  `support_vectors_` : array-like, shape = [nSV, n_features]\n",
        "     |      Support vectors.\n",
        "     |  \n",
        "     |  `dual_coef_` : array, shape = [n_classes-1, n_SV]\n",
        "     |      Coefficients of the support vector in the decision function.\n",
        "     |  \n",
        "     |  `coef_` : array, shape = [n_classes-1, n_features]\n",
        "     |      Weights asigned to the features (coefficients in the primal\n",
        "     |      problem). This is only available in the case of linear kernel.\n",
        "     |  \n",
        "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
        "     |      `support_vectors_`\n",
        "     |  \n",
        "     |  `intercept_` : array, shape = [n_class * (n_class-1) / 2]\n",
        "     |      Constants in decision function.\n",
        "     |  \n",
        "     |  Examples\n",
        "     |  --------\n",
        "     |  >>> from sklearn.svm import SVR\n",
        "     |  >>> import numpy as np\n",
        "     |  >>> n_samples, n_features = 10, 5\n",
        "     |  >>> np.random.seed(0)\n",
        "     |  >>> y = np.random.randn(n_samples)\n",
        "     |  >>> X = np.random.randn(n_samples, n_features)\n",
        "     |  >>> clf = SVR(C=1.0, epsilon=0.2)\n",
        "     |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
        "     |  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma=0.0,\n",
        "     |    kernel='rbf', max_iter=-1, probability=False, shrinking=True, tol=0.001,\n",
        "     |    verbose=False)\n",
        "     |  \n",
        "     |  See also\n",
        "     |  --------\n",
        "     |  NuSVR\n",
        "     |      Support Vector Machine for regression implemented using libsvm\n",
        "     |      using a parameter to control the number of support vectors.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      SVR\n",
        "     |      sklearn.svm.base.BaseLibSVM\n",
        "     |      sklearn.base.BaseEstimator\n",
        "     |      sklearn.base.RegressorMixin\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, probability=False, cache_size=200, verbose=False, max_iter=-1)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  __abstractmethods__ = frozenset([])\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  decision_function(self, X)\n",
        "     |      Distance of the samples X to the separating hyperplane.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      X : array-like, shape = [n_samples, n_class * (n_class-1) / 2]\n",
        "     |          Returns the decision function of the sample for each class\n",
        "     |          in the model.\n",
        "     |  \n",
        "     |  fit(self, X, y, sample_weight=None)\n",
        "     |      Fit the SVM model according to the given training data.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |          Training vectors, where n_samples is the number of samples\n",
        "     |          and n_features is the number of features.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |          Target values (class labels in classification, real numbers in\n",
        "     |          regression)\n",
        "     |      \n",
        "     |      sample_weight : array-like, shape = [n_samples], optional\n",
        "     |          Weights applied to individual samples (1. for unweighted).\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self : object\n",
        "     |          Returns self.\n",
        "     |      \n",
        "     |      Notes\n",
        "     |      ------\n",
        "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
        "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
        "     |      \n",
        "     |      If X is a dense array, then the other methods will not support sparse\n",
        "     |      matrices as input.\n",
        "     |  \n",
        "     |  predict(self, X)\n",
        "     |      Perform regression on samples in X.\n",
        "     |      \n",
        "     |      For an one-class model, +1 or -1 is returned.\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      y_pred : array, shape = [n_samples]\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  coef_\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes inherited from sklearn.svm.base.BaseLibSVM:\n",
        "     |  \n",
        "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
        "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
        "     |      \n",
        "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
        "     |      directly, and then acts as a mix-in class.  You can also register\n",
        "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
        "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
        "     |      be considered subclasses of the registering ABC by the built-in\n",
        "     |      issubclass() function, but the registering ABC won't show up in\n",
        "     |      their MRO (Method Resolution Order) nor will method\n",
        "     |      implementations defined by the registering ABC be callable (not\n",
        "     |      even via super()).\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  __str__(self)\n",
        "     |  \n",
        "     |  get_params(self, deep=True)\n",
        "     |      Get parameters for the estimator\n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      deep: boolean, optional\n",
        "     |          If True, will return the parameters for this estimator and\n",
        "     |          contained subobjects that are estimators.\n",
        "     |  \n",
        "     |  set_params(self, **params)\n",
        "     |      Set the parameters of the estimator.\n",
        "     |      \n",
        "     |      The method works on simple estimators as well as on nested objects\n",
        "     |      (such as pipelines). The former have parameters of the form\n",
        "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
        "     |      component of a nested object.\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      self\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
        "     |  \n",
        "     |  score(self, X, y)\n",
        "     |      Returns the coefficient of determination R^2 of the prediction.\n",
        "     |      \n",
        "     |      The coefficient R^2 is defined as (1 - u/v), where u is the regression\n",
        "     |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual\n",
        "     |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
        "     |      Best possible score is 1.0, lower values are worse.\n",
        "     |      \n",
        "     |      \n",
        "     |      Parameters\n",
        "     |      ----------\n",
        "     |      X : array-like, shape = [n_samples, n_features]\n",
        "     |          Training set.\n",
        "     |      \n",
        "     |      y : array-like, shape = [n_samples]\n",
        "     |      \n",
        "     |      Returns\n",
        "     |      -------\n",
        "     |      z : float\n",
        "\n",
        "FUNCTIONS\n",
        "    l1_min_c(X, y, loss='l2', fit_intercept=True, intercept_scaling=1.0)\n",
        "        Return the lowest bound for C such that for C in (l1_min_C, infinity)\n",
        "        the model is guaranteed not to be empty. This applies to l1 penalized\n",
        "        classifiers, such as LinearSVC with penalty='l1' and\n",
        "        linear_model.LogisticRegression with penalty='l1'.\n",
        "        \n",
        "        This value is valid if class_weight parameter in fit() is not set.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
        "            Training vector, where n_samples in the number of samples and\n",
        "            n_features is the number of features.\n",
        "        \n",
        "        y : array, shape = [n_samples]\n",
        "            Target vector relative to X\n",
        "        \n",
        "        loss : {'l2', 'log'}, default to 'l2'\n",
        "            Specifies the loss function.\n",
        "            With 'l2' it is the l2 loss (a.k.a. squared hinge loss).\n",
        "            With 'log' it is the loss of logistic regression models.\n",
        "        \n",
        "        fit_intercept : bool, default: True\n",
        "            Specifies if the intercept should be fitted by the model.\n",
        "            It must match the fit() method paramenter.\n",
        "        \n",
        "        intercept_scaling : float, default: 1\n",
        "            when fit_intercept is True, instance vector x becomes\n",
        "            [x, intercept_scaling],\n",
        "            i.e. a \"synthetic\" feature with constant value equals to\n",
        "            intercept_scaling is appended to the instance vector.\n",
        "            It must match the fit() method parameter.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        l1_min_c: float\n",
        "            minimum value for C\n",
        "\n",
        "DATA\n",
        "    __all__ = ['LinearSVC', 'NuSVC', 'NuSVR', 'OneClassSVM', 'SVC', 'SVR',...\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}